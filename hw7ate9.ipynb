{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46298283-418e-47ea-ba08-d9f6c9c62a25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d023c8-3ed0-4e39-a07c-82fe8b4e8a4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Theoretical Simple Linear Regression Model and Python Simulation\r\n",
    "\r\n",
    "*   **Simple Linear Regression** is a statistical model that assumes a linear relationship between a predictor variable ($x_i$) and an outcome variable ($Y_i$). It uses an error term ($\\epsilon_i$) to account for random variation in the outcome variable that is not explained by the predictor.\r\n",
    "\r\n",
    "*   This relationship can be expressed as:  $Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$.\r\n",
    "    *   $Y_i$ is the outcome variable. It is also sometimes called a response, dependent or endogenous variable.\r\n",
    "    *   $x_i$ is the predictor variable. It is also sometimes called an explanatory, independent or exogenous variable, or a covariate or feature.\r\n",
    "    *   $\\beta_0$ is the intercept coefficient. It represents the expected value of $Y_i$ when $x_i$ is 0.\r\n",
    "    *   $\\beta_1$ is the slope coefficient. It represents the expected change in $Y_i$ for a one-unit increase in $x_i$.\r\n",
    "    *   $\\epsilon_i$ is the error term. It is assumed to be normally distributed with a mean of 0 and a standard deviation of $\\sigma$ (i.e., $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma)$).\r\n",
    "\r\n",
    "*   The **theoretical Simple Linear Regression model** assumes that the outcome variable ($Y_i$) is a **continuous numeric variable**, and the predictor variable ($x_i$) is a **numeric variable** (which can be either **continuous** or **categorical**). The sources note that the model makes several assumptions about the error term ($\\epsilon_i$) which are not the focus of the response, but these assumptions are provided for you to review if you like.\r\n",
    "\r\n",
    "*   The **Simple Linear Regression** model equation can be used to generate simulated data by first fixing the values of the predictor variable ($x_i$), then generating random values for the error term ($\\epsilon_i$) from a normal distribution, and finally calculating the values of the outcome variable ($Y_i$) using the model equation.\r\n",
    "\r\n",
    "Below is Python code that demonstrates how to simulate data from the **theoretical Simple Linear Regression model** using NumPy and SciPy.stats:\r\n",
    "\r\n",
    "```python\r\n",
    "import numpy as np\r\n",
    "from scipy import stats\r\n",
    "import plotly.express as px\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Set the parameters of the model\r\n",
    "n = 100  # sample size\r\n",
    "beta0 = 2  # intercept\r\n",
    "beta1 = 3  # slope\r\n",
    "sigma = 1  # standard deviation of the error term\r\n",
    "\r\n",
    "# Generate the predictor variable\r\n",
    "x = stats.uniform.rvs(size=n)\r\n",
    "\r\n",
    "# Generate the error term\r\n",
    "errors = stats.norm.rvs(loc=0, scale=sigma, size=n)\r\n",
    "\r\n",
    "# Calculate the outcome variable\r\n",
    "Y = beta0 + beta1 * x + errors\r\n",
    "\r\n",
    "# Create a Pandas DataFrame\r\n",
    "df = pd.DataFrame({'x': x, 'Y': Y})\r\n",
    "\r\n",
    "# Visualize the simulated data\r\n",
    "fig = px.scatter(df, x='x', y='Y', trendline='ols')\r\n",
    "fig.show()\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10042418-bb0c-467f-89b0-053cef8c41e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f4483-c0fa-49f5-9abc-21ef3e6af216",
   "metadata": {},
   "source": [
    "Using Simulated Data to Fit and Visualize a Simple Linear Regression Model\r\n",
    "\r\n",
    "Using the simulated dataset you created in the previous step, you can now demonstrate how to create and visualize a fitted simple linear regression model using *pandas* and *statsmodels.formula.api as smf*. Here's how you can do that, building on the Python code from our previous conversation:\r\n",
    "\r\n",
    "```python\r\n",
    "import numpy as np\r\n",
    "from scipy import stats\r\n",
    "import plotly.express as px\r\n",
    "import pandas as pd\r\n",
    "import statsmodels.formula.api as smf\r\n",
    "\r\n",
    "# Set the parameters of the model\r\n",
    "n = 100  # sample size\r\n",
    "beta0 = 2  # intercept\r\n",
    "beta1 = 3  # slope\r\n",
    "sigma = 1  # standard deviation of the error term\r\n",
    "\r\n",
    "# Generate the predictor variable\r\n",
    "x = stats.uniform.rvs(size=n)\r\n",
    "\r\n",
    "# Generate the error term\r\n",
    "errors = stats.norm.rvs(loc=0, scale=sigma, size=n)\r\n",
    "\r\n",
    "# Calculate the outcome variable\r\n",
    "Y = beta0 + beta1 * x + errors\r\n",
    "\r\n",
    "# Create a Pandas DataFrame\r\n",
    "df = pd.DataFrame({'x': x, 'Y': Y})\r\n",
    "\r\n",
    "# Fit the Simple Linear Regression Model\r\n",
    "fitted_model = smf.ols('Y ~ x', data=df).fit()\r\n",
    "\r\n",
    "# Print the fitted model summary\r\n",
    "print(fitted_model.summary())\r\n",
    "\r\n",
    "# Visualize the fitted model\r\n",
    "fig = px.scatter(df, x='x', y='Y', trendline='ols')\r\n",
    "fig.show()\r\n",
    "```\r\n",
    "\r\n",
    "*   **Fitting the model:** The line `fitted_model = smf.ols('Y ~ x', data=df).fit()` fits a simple linear regression model to the simulated data in the *pandas* DataFrame `df` using the `smf.ols()` function. \r\n",
    "    *   The `'Y ~ x'` argument is an **R-style formula** that specifies the linear form of the model, with the outcome variable (`Y`) on the left and the predictor variable (`x`) on the right.\r\n",
    "    *   The `.fit()` **method** estimates the model parameters—in this case, the intercept ($\\hat{\\beta}_0$) and slope ($\\hat{\\beta}_1$) coefficients—that best fit the data according to the **ordinary least squares** method. This results in the creation of the **fitted model** object `fitted_model`, which contains all the information about the fitted model.\r\n",
    "\r\n",
    "*   **Visualizing the model:**  The line `fig = px.scatter(df, x='x', y='Y', trendline='ols')` creates a scatter plot of the simulated data and adds a trendline representing the fitted regression model using the `trendline='ols'` argument in the `px.scatter()` function. The sources note that the **ordinary least squares** (`ols`) method is used both to fit the model in `smf.ols()` and to create the trendline.\r\n",
    "\r\n",
    "*   **Viewing results:** The line `print(fitted_model.summary())` prints a comprehensive summary of the fitted model. This summary provides information about the estimated coefficients, their standard errors, p-values for hypothesis tests on the coefficients, and other model statistics like R-squared.\r\n",
    "\r\n",
    "This code demonstrates how to create and visualize a fitted simple linear regression model based on your simulated data, mirroring the process used to fit and visualize models based on real-world data. You can experiment with modifying the parameters of the theoretical model (like `n`, `beta0`, `beta1`, and `sigma`) to explore how they impact the fitted model and its visualization.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41851aa-7c4d-4eee-9f25-e5d6c599a49c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc7005-ad9b-4eaa-a3da-c2162da3fcfa",
   "metadata": {},
   "source": [
    "Adding the Theoretical Line and Explaining the Difference\r\n",
    "\r\n",
    "You want to add the line from your first query, which represented the theoretical simple linear regression model, to the plot from your second query, which showed the fitted model for a simulated dataset. Here's how you can do that, along with an explanation of the differences between the two lines. \r\n",
    "\r\n",
    "#### Python Code\r\n",
    "\r\n",
    "This code adds the theoretical line (in red) to the plot of the fitted model (using the code we created together in our previous conversation):\r\n",
    "\r\n",
    "```python\r\n",
    "import numpy as np\r\n",
    "from scipy import stats\r\n",
    "import plotly.express as px\r\n",
    "import pandas as pd\r\n",
    "import statsmodels.formula.api as smf\r\n",
    "\r\n",
    "# Set the parameters of the model\r\n",
    "n = 100  # sample size\r\n",
    "beta0 = 2  # intercept\r\n",
    "beta1 = 3  # slope\r\n",
    "sigma = 1  # standard deviation of the error term\r\n",
    "\r\n",
    "# Generate the predictor variable\r\n",
    "x = stats.uniform.rvs(size=n)\r\n",
    "\r\n",
    "# Generate the error term\r\n",
    "errors = stats.norm.rvs(loc=0, scale=sigma, size=n)\r\n",
    "\r\n",
    "# Calculate the outcome variable\r\n",
    "Y = beta0 + beta1 * x + errors\r\n",
    "\r\n",
    "# Create a Pandas DataFrame\r\n",
    "df = pd.DataFrame({'x': x, 'Y': Y})\r\n",
    "\r\n",
    "# Fit the Simple Linear Regression Model\r\n",
    "fitted_model = smf.ols('Y ~ x', data=df).fit()\r\n",
    "\r\n",
    "# Print the fitted model summary\r\n",
    "print(fitted_model.summary())\r\n",
    "\r\n",
    "# Visualize the fitted model\r\n",
    "fig = px.scatter(df, x='x', y='Y', trendline='ols')\r\n",
    "\r\n",
    "# Add the theoretical line\r\n",
    "x_range = np.linspace(0, 1, 10)  # Create a range of x-values for the line\r\n",
    "theoretical_y = beta0 + beta1 * x_range  # Calculate the theoretical Y values using the true model parameters\r\n",
    "fig.add_scatter(x=x_range, y=theoretical_y, mode='lines', line=dict(color='red'), name='Theoretical Line')\r\n",
    "\r\n",
    "fig.show()\r\n",
    "```\r\n",
    "\r\n",
    "#### Explanation of the Difference Between the Lines\r\n",
    "\r\n",
    "The two lines on the plot represent distinct but related concepts:\r\n",
    "\r\n",
    "*   **The blue line** is the fitted regression line, calculated from the simulated data using the `smf.ols()` function and the **ordinary least squares** (`ols`) method. This line represents the best linear fit *to the specific sample of data* that you simulated. The blue line is an *estimate* of the true relationship between the predictor and outcome variables, but it is influenced by the random variation present in your sample.\r\n",
    "\r\n",
    "*   **The red line** is the theoretical regression line, based on the parameters you set when generating the simulated data (specifically, `beta0` and `beta1`).  The red line represents the true underlying relationship between the predictor and outcome variables in the **population** from which you are simulating your data. \r\n",
    "\r\n",
    "**Key Difference:** The difference between the two lines is due to random sampling variation.  Because your simulated dataset is a sample, it will not perfectly reflect the true population relationship, which is represented by the theoretical (red) line. The fitted (blue) line is adjusted based on the specific random errors present in your sample, and therefore it deviates slightly from the true line.\r\n",
    "\r\n",
    "**Why the difference matters:** Understanding this difference is crucial because it highlights a fundamental concept in statistics:\r\n",
    "\r\n",
    "*   We use sample data to make inferences about populations.\r\n",
    "*   These inferences are always subject to some degree of uncertainty due to sampling variation.\r\n",
    "\r\n",
    "The comparison between the theoretical and fitted lines visually demonstrates this uncertainty, helping you to grasp the idea that statistical models are estimations based on available data and are not necessarily perfect representations of the true underlying relationships in the population.\r\n",
    "\r\n",
    "#### Visualizing Random Sampling Variation \r\n",
    "\r\n",
    "The sources recommend repeatedly simulating datasets from your theoretical model and fitting a new model each time to visualize random sampling variation. By doing so, you will see that the fitted line will change slightly with each simulation, illustrating the inherent variability in estimates based on different samples. \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb857291-e133-4ff7-95b3-0bf39a9918c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f958c-b016-437e-9b07-5dcbd70dfbf9",
   "metadata": {},
   "source": [
    "How `fitted_model.fittedvalues` Are Derived\r\n",
    "\r\n",
    "**`fitted_model.fittedvalues` are the predicted values of the outcome variable (Y) for each observation in the dataset based on the fitted simple linear regression model.** These values are calculated using the fitted model's intercept and slope coefficients, which are stored in `fitted_model.params`.\r\n",
    "\r\n",
    "**Here's how the process works, drawing on our conversation history and the sources:**\r\n",
    "\r\n",
    "1.  **You fit a simple linear regression model to a dataset:** As we saw in our previous conversation, this is done in Python using the `smf.ols()` function from the *statsmodels* package. This function uses the **ordinary least squares** (`ols`) method to estimate the intercept ($\\hat{\\beta}_0$) and slope ($\\hat{\\beta}_1$) coefficients that best fit the data, resulting in the creation of a `fitted_model` object.\r\n",
    "\r\n",
    "2.  **The fitted model object stores the estimated coefficients:** These coefficients are accessible through the `.params` attribute of the `fitted_model` object. You can either access the entire `fitted_model.params` object, which provides both the intercept and slope, or you can specifically access the values using `fitted_model.params.values`.\r\n",
    "\r\n",
    "3.  **The fitted values are calculated using these coefficients and the predictor variable (x):** The fitted values ($\\hat{y}_i$) are obtained by plugging the values of the predictor variable ($x_i$) into the fitted model equation: $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$. This calculation is performed for each observation in the dataset, resulting in a vector of fitted values with the same length as the original outcome variable (Y).\r\n",
    "\r\n",
    "4.  **The fitted values are stored in the `.fittedvalues` attribute:** These calculated fitted values can be directly accessed using the `fitted_model.fittedvalues` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ebbcff-803b-468a-b97c-4181719629a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93822347-f253-4a01-a95d-1d14d4320c41",
   "metadata": {},
   "source": [
    "How the \"Best Fit\" Line is Determined Using Ordinary Least Squares\r\n",
    "\r\n",
    "The **ordinary least squares (OLS)** method is used to determine the \"best fit\" line for a simple linear regression model. This line aims to represent the linear relationship between the predictor variable (x) and the outcome variable (Y) in a way that minimizes the overall difference between the observed Y values and the values predicted by the line.\r\n",
    "\r\n",
    "The OLS method achieves this by **minimizing the sum of the squared residuals**. A **residual** is the vertical distance between an observed data point and the fitted line, representing the difference between the observed Y value ($Y_i$) and the predicted Y value ($\\hat{y}_i$) for a given x value. \r\n",
    "\r\n",
    "*   The line that results in the smallest sum of these squared residuals is considered the \"best fit\" line because it minimizes the overall discrepancy between the model's predictions and the actual data.\r\n",
    "\r\n",
    "**Here's why \"squares\" are necessary:**\r\n",
    "\r\n",
    "*   **Avoiding cancellation of positive and negative residuals:**  If we simply summed the residuals without squaring them, positive and negative residuals could cancel each other out, potentially leading to a line that doesn't accurately represent the overall trend in the data.\r\n",
    "*   **Emphasizing larger errors:** Squaring the residuals gives more weight to larger errors, ensuring that the OLS method prioritizes finding a line that minimizes these substantial deviations from the observed data.\r\n",
    "\r\n",
    "The use of \"squares\" in the ordinary least squares method provides a mathematically rigorous way to find the line that best fits the data, considering both the direction and magnitude of the differences between the observed values and the model's predictions. \r\n",
    "\r\n",
    "**The sources explain that both the `trendline='ols'` argument in *plotly.express* scatter plots and the `smf.ols(...).fit()` function in *statsmodels* use the OLS method to determine the fitted regression line.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59caf364-66b2-42fc-965f-823eff473b95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c76438-ccf0-41c5-a71c-feba208c44df",
   "metadata": {},
   "source": [
    "Understanding R-Squared and the Proportion of Variation Explained by a Simple Linear Regression Model\r\n",
    "\r\n",
    "Let's break down how the provided expressions relate to R-squared and its interpretation in simple linear regression. \r\n",
    "\r\n",
    "*   **`1-((Y-fitted_model.fittedvalues)**2).sum()/((Y-Y.mean())**2).sum()`**\r\n",
    "\r\n",
    "    This expression is a direct calculation of R-squared. It represents **the proportion of the total variation in the outcome variable (Y) that is explained by the fitted simple linear regression model**. Let's understand it piece by piece:\r\n",
    "\r\n",
    "    *   `(Y-fitted_model.fittedvalues)**2`: This calculates the squared **residuals** for each observation.  A residual, as we discussed previously, is the difference between the observed Y value and the predicted Y value (from `fitted_model.fittedvalues`) for a given x value. Squaring the residuals ensures that we are considering the magnitude of the differences and avoids cancellation of positive and negative values. \r\n",
    "\r\n",
    "    *   `((Y-fitted_model.fittedvalues)**2).sum()`: This sums the squared residuals across all observations, giving us a measure of the **total unexplained variation** in Y – that is, the variation that the model cannot account for.\r\n",
    "\r\n",
    "    *   `(Y-Y.mean())**2`.sum()`: This calculates the sum of squared differences between each observed Y value and the mean of Y. This represents the **total variation** in Y.\r\n",
    "\r\n",
    "    *   `1-((Y-fitted_model.fittedvalues)**2).sum()/((Y-Y.mean())**2).sum()`: By subtracting the ratio of unexplained variation to total variation from 1, we arrive at **the proportion of variation in Y that *is* explained by the model**, which is the definition of R-squared.\r\n",
    "\r\n",
    "*   **`fitted_model.rsquared`**\r\n",
    "\r\n",
    "    This is a convenient way to access the **R-squared value directly from the fitted model object**. The source material indicates that this attribute provides the same value as calculated in the first expression.\r\n",
    "\r\n",
    "*   **`np.corrcoef(Y,fitted_model.fittedvalues)**2`**\r\n",
    "\r\n",
    "    This expression calculates **the squared correlation coefficient between the observed Y values and the fitted values from the model**. Squaring the correlation coefficient gives us R-squared. This highlights that:\r\n",
    "\r\n",
    "    *   R-squared is directly related to the strength of the linear relationship between the predicted values from the model and the actual observed values.\r\n",
    "    *   A higher R-squared indicates that the model's predictions are more closely aligned with the observed outcomes.\r\n",
    "\r\n",
    "*   **`np.corrcoef(Y,x)**2`**\r\n",
    "\r\n",
    "    This expression calculates **the squared correlation coefficient between the observed Y values and the predictor variable (x)**. In simple linear regression, this value is also equal to R-squared. This demonstrates:\r\n",
    "\r\n",
    "    *   The strength of the linear relationship between the predictor and outcome variables is directly reflected in the model's ability to explain variation in the outcome.\r\n",
    "\r\n",
    "#### What This Means About R-Squared as a Measure of Accuracy\r\n",
    "\r\n",
    "In the context of simple linear regression, **R-squared can be interpreted as a measure of the accuracy of the model** because it tells us how well the fitted line represents the overall linear trend in the data.\r\n",
    "\r\n",
    "*   A **higher R-squared value** indicates that the model explains a greater proportion of the variation in the outcome variable, suggesting a better fit to the data and more accurate predictions.\r\n",
    "*   A **lower R-squared value** indicates that the model explains less of the variation, suggesting a poorer fit and less accurate predictions.\r\n",
    "\r\n",
    "However, it's important to note that while R-squared is a helpful metric, it's not the only consideration when evaluating a model. Other factors, such as the **assumptions of the simple linear regression model** and the context of the data, are also essential to consider. \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097677a-9596-49d8-b89e-f27c3e03d555",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d96da9-3c50-478f-8716-927045fea7be",
   "metadata": {},
   "source": [
    "Assumptions of Simple Linear Regression and Their Compatibility with the Example Data\r\n",
    "\r\n",
    "Several assumptions underpin the Simple Linear Regression model.  Let's examine a couple that might not align well with the provided data, keeping in mind that you have not included the example data in your query.\r\n",
    "\r\n",
    "*   **Normally Distributed Errors:** The Simple Linear Regression model assumes that the errors, represented by $\\epsilon_i$ in the equation $Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$, are normally distributed. This means that the vertical spread of the data points around the fitted regression line should follow a bell-shaped curve.\r\n",
    "\r\n",
    "    *   **How to Check for Compatibility Issues:** To assess this assumption, you would typically examine the distribution of the **residuals**  ($\\text{e}_i = \\hat \\epsilon_i = y_i - \\hat y_i$). If the histogram of the residuals displays a clear departure from a normal distribution, such as being heavily skewed or having multiple peaks, it suggests that this assumption might not hold for the data.\r\n",
    "*   **Homoscedasticity (Constant Variance of Errors):** Another crucial assumption is homoscedasticity, which means that the variance of the errors remains constant across all values of the predictor variable ($x_i$). This implies that the spread of the data points around the fitted line should be roughly the same across the entire range of x values.\r\n",
    "\r\n",
    "    *   **How to Check for Compatibility Issues:** You can visually inspect this assumption by examining a scatter plot of the data with the fitted regression line. If the spread of the data points appears to systematically increase or decrease as x increases, it indicates heteroscedasticity (non-constant variance) and a potential violation of this assumption.\r\n",
    "\r\n",
    "**Without the example data, it's impossible to definitively state whether these assumptions are compatible.** However, these are important aspects to consider when evaluating the validity of a Simple Linear Regrese specifically.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b948e-8dc2-44b2-9979-8291c30090c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8275e-9915-4cc8-8101-c81dbd5ceb93",
   "metadata": {},
   "source": [
    "Hypothesis Testing for Linear Association in the Old Faithful Geyser Dataset\r\n",
    "\r\n",
    "*   **Null Hypothesis:** The null hypothesis of \"no linear association (on average)\" between eruption duration and waiting time in the Old Faithful Geyser dataset can be stated in terms of the **slope coefficient** ($\\beta_1$) of the Simple Linear Regression model:\r\n",
    "\r\n",
    "$H_0: \\beta_1 = 0$.\r\n",
    "\r\n",
    "*   This null hypothesis posits that there is **no systematic change in eruption duration (on average) for a unit increase in waiting time**.\r\n",
    "\r\n",
    "*   **Using the Code to Assess the Null Hypothesis:**  You have provided code, but it is missing from your query.   To characterize the evidence in the data against the null hypothesis, you would need to use the following steps, drawing upon the methods described in the sources:\r\n",
    "\r\n",
    "1.   **Fit a Simple Linear Regression model** to the Old Faithful Geyser dataset using the code:\r\n",
    "`fitted_model = smf. ols('duration ~ waiting', data=old_faithful).fit()`.\r\n",
    "\r\n",
    "2.   **Access the p-value** associated with the slope coefficient from the model summary table:\r\n",
    "`p_value = fitted_model.summary().tables['P>|t|']`.\r\n",
    "\r\n",
    "3.   **Interpret the p-value** in terms of the strength of evidence against the null hypothesis using the table provided in the sources:\r\n",
    "\r\n",
    "| p-value            | Evidence                                      |\r\n",
    "| :----------------- | :------------------------------------------- |\r\n",
    "|  *p* > 0.1         | No evidence against the null hypothesis      |\r\n",
    "| 0.1 ≥  *p* > 0.05 | Weak evidence against the null hypothesis     |\r\n",
    "| 0.05 ≥  *p* > 0.01 | Moderate evidence against the null hypothesis |\r\n",
    "| 0.01 ≥  *p* > 0.001 | Strong evidence against the null hypothesis  |\r\n",
    "| 0.001 ≥  *p*       | Very strong evidence against the null hypothesis |\r\n",
    "\r\n",
    "*   **Interpreting Beliefs Based on the Evidence:**\r\n",
    "\r\n",
    "*   If the **p-value is small** (e.g., less than a chosen significance level of 0.05), you would **reject the null hypothesis**, concluding that there is evidence for a linear association between eruption duration and waiting time in the Old Faithful Geyser dataset.  This would suggest that, on average, longer waiting times are associated with longer eruption durations.\r\n",
    "\r\n",
    "*   If the **p-value is large** (e.g., greater than 0.05), you would **fail to reject the null hypothesis**.   This means you don't have sufficient evidence to conclude that a linear association exists.  However, it's important to remember that this doesn't prove the null hypothesis is true;  it just means the data doesn't provide strong enough evidence to reject it.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5069f-641a-49ae-90c6-b7c3db199c00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e5b0b-4b16-4776-aff9-c9aa566df415",
   "metadata": {},
   "source": [
    "Analyzing the Old Faithful Geyser Dataset: Evidence for Linear Association with Short Wait Times\r\n",
    "\r\n",
    "#### Applying the Code and Interpreting the Output\r\n",
    "\r\n",
    "The code you provided performs the following actions:\r\n",
    "\r\n",
    "1.    **Defines `short_wait_limit`:** This variable sets the threshold for what's considered a \"short\" waiting time.    You've provided three values to explore: 62, 64, and 66 minutes.\r\n",
    "2.    **Creates a Boolean Mask:** `short_wait = old_faithful.  waiting < short_wait_limit` creates a True/False mask that identifies observations where the waiting time is below the `short_wait_limit`.\r\n",
    "3.    **Fits Simple Linear Regression Models:**  The code then fits separate simple linear regression models for each `short_wait_limit` value, using only the data points that meet the short wait time criterion:\r\n",
    "`smf.  ols('duration ~ waiting', data=old_faithful[short_wait]).fit()`.\r\n",
    "4.    **Prints the Model Summary Table:**  `print(smf.  ols('duration ~ waiting', data=old_faithful[short_wait]).fit().summary().tables)` displays the summary table for the fitted model, including the p-value associated with the slope coefficient.    This p-value will be key to assessing the null hypothesis.\r\n",
    "5.    **Generates Scatter Plots:**  For each `short_wait_limit`, the code creates a scatter plot of eruption duration versus waiting time, restricted to the short wait times, and overlays the fitted regression line (`trendline='ols'`).\r\n",
    "\r\n",
    "#### Interpreting the Results and Addressing the Null Hypothesis\r\n",
    "\r\n",
    "To fully answer your query, you would need to **run the code and examine the output, particularly the p-values from the model summaries**.   Here's how to interpret the results in the context of the null hypothesis:\r\n",
    "\r\n",
    "*   **Null Hypothesis:**  Recall from our previous conversation that the null hypothesis of \"no linear association (on average)\" is stated as $H_0: \\beta_1 = 0$, where $\\beta_1$ is the slope coefficient of the Simple Linear Regression model.\r\n",
    "\r\n",
    "*   **Assessing the Evidence:** Using the p-value associated with the slope coefficient for each `short_wait_limit` from the model summary tables, you can determine the strength of the evidence against the null hypothesis using the table we discussed earlier:\r\n",
    "\r\n",
    "| p-value            | Evidence                                      |\r\n",
    "| :----------------- | :------------------------------------------- |\r\n",
    "|  *p* > 0.1         | No evidence against the null hypothesis      |\r\n",
    "| 0.1 ≥  *p* > 0.05 | Weak evidence against the null hypothesis     |\r\n",
    "| 0.05 ≥  *p* > 0.01 | Moderate evidence against the null hypothesis |\r\n",
    "| 0.01 ≥  *p* > 0.001 | Strong evidence against the null hypothesis  |\r\n",
    "| 0.001 ≥  *p*       | Very strong evidence against the null hypothesis |\r\n",
    "\r\n",
    "*   **Drawing Conclusions:**\r\n",
    "\r\n",
    "*   **Small p-value:** If the p-value is small (typically below a pre-determined significance level such as 0.05), you would **reject the null hypothesis**.   This would indicate that there is evidence for a linear association between eruption duration and waiting time, even when considering only short wait times.   The scatter plots would likely show a clear upward or downward trend, supporting the conclusion.\r\n",
    "*   **Large p-value:**  If the p-value is large (above the significance level), you would **fail to reject the null hypothesis**.   This means the data does not provide sufficient evidence to conclude that a linear association exists within the short wait times.   The scatter plots might show a random scattering of points with no clear trend.\r\n",
    "\r\n",
    "#### Key Considerations\r\n",
    "\r\n",
    "As you analyze the results, keep these points in mind:\r\n",
    "\r\n",
    "*   **Impact of `short_wait_limit`:** The choice of `short_wait_limit` will affect the data included in each analysis and could influence the conclusions.   Pay attention to how the results and the scatter plots change with different threshold values.\r\n",
    "*   **Non-Linear Relationships:** The introductory figure you mentioned suggests a potential non-linear relationship in the full dataset.    It's possible that restricting to short wait times could still reveal a non-linear pattern, even if a linear association is not statistically significant.   Carefully examine the scatter plots for any signs of curvature or non-linear trends.\r\n",
    "\r\n",
    "**Once you run the code and examine the output, you can determine the p-values for each `short_wait_limit` and draw specific conclusions about the evidence for a linear association within the context of short waiting times.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0098a3-37dd-4f5a-bbbf-4383ee27f135",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d480810b-1c88-4f87-b41f-f0042331dc39",
   "metadata": {},
   "source": [
    "Bootstrapped and Simulated Sampling Distributions of Slope Coefficients for Long Wait Times in the Old Faithful Geyser Dataset\r\n",
    "\r\n",
    "This response will analyze the relationship between eruption duration and waiting time for long wait times in the Old Faithful Geyser dataset by creating and comparing bootstrapped and simulated sampling distributions of fitted slope coefficients. It will also determine if 0 is contained within a 95% bootstrapped confidence interval and compare a simulated p-value to the p-value reported by `smf.ols`.\r\n",
    "\r\n",
    "#### **Step 1: Create a Subset for Long Wait Times**\r\n",
    "\r\n",
    "First, create a subset of the data containing only the long wait times. You can use the code provided in your query and the information from our previous conversation, which suggested using a wait time greater than 71 minutes as a criterion for long wait times.\r\n",
    "\r\n",
    "```python\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import statsmodels.formula.api as smf\r\n",
    "from scipy import stats\r\n",
    "\r\n",
    "# ... (Assuming old_faithful DataFrame is already loaded)\r\n",
    "\r\n",
    "long_wait = old_faithful.waiting > 71\r\n",
    "long_wait_data = old_faithful[long_wait]\r\n",
    "```\r\n",
    "\r\n",
    "#### **Step 2: Generate Bootstrapped Samples and Calculate Fitted Slope Coefficients**\r\n",
    "\r\n",
    "The sources describe the concept of bootstrapping, which involves repeatedly resampling from the original sample with replacement. To create the bootstrapped sampling distribution of fitted slope coefficients, you will:\r\n",
    "\r\n",
    "1.  **Create bootstrapped samples:** Repeatedly draw samples of size `n = 160` (the number of long wait times) with replacement from the `long_wait_data` subset.  You can use the `pandas.DataFrame.sample()` method with `replace=True` for this.\r\n",
    "2.  **Fit Simple Linear Regression models:** For each bootstrapped sample, fit a Simple Linear Regression model using `smf.ols('duration ~ waiting', data=bootstrapped_sample).fit()`.\r\n",
    "3.  **Collect fitted slope coefficients:** Extract the fitted slope coefficient from each fitted model (e.g., using `fitted_model.params`) and store them in a list or NumPy array.\r\n",
    "\r\n",
    "The following code snippet demonstrates these steps:\r\n",
    "\r\n",
    "```python\r\n",
    "n_bootstrap_samples = 1000  # Adjust the number of bootstrap samples as needed\r\n",
    "bootstrapped_slope_coefficients = []\r\n",
    "\r\n",
    "for _ in range(n_bootstrap_samples):\r\n",
    "    bootstrapped_sample = long_wait_data.sample(n=long_wait.sum(), replace=True)\r\n",
    "    fitted_model = smf.ols('duration ~ waiting', data=bootstrapped_sample).fit()\r\n",
    "    bootstrapped_slope_coefficients.append(fitted_model.params)\r\n",
    "```\r\n",
    "\r\n",
    "#### **Step 3: Simulate Data Under the Null Hypothesis and Calculate Fitted Slope Coefficients**\r\n",
    "\r\n",
    "To simulate data under the null hypothesis of no linear association, you will generate new eruption duration values ($Y_i$) based on a Simple Linear Regression model with $\\beta_1 = 0$. You've specified the following parameter values in your query:\r\n",
    "\r\n",
    "*   $\\beta_0 = 1.65$\r\n",
    "*   $\\beta_1 = 0$\r\n",
    "*   $\\sigma = 0.37$\r\n",
    "\r\n",
    "Follow these steps to generate simulated data and calculate fitted slope coefficients:\r\n",
    "\r\n",
    "1.  **Create a copy of the data:** Create a copy of the `long_wait_data` subset to store the simulated data: `simulated_data = long_wait_data.copy()`.\r\n",
    "2.  **Generate simulated eruption durations:** Generate simulated eruption duration values using the formula:\r\n",
    "    `simulated_data['duration'] = 1.65 + 0 * simulated_data.waiting + stats.norm(loc=0, scale=0.37).rvs(size=long_wait.sum())`. This formula reflects a Simple Linear Regression model with no linear association because the slope coefficient ($\\beta_1$) is set to 0.\r\n",
    "3.  **Fit Simple Linear Regression models:** For each simulated dataset, fit a Simple Linear Regression model using `smf.ols('duration ~ waiting', data=simulated_data).fit()`.\r\n",
    "4.  **Collect fitted slope coefficients:**  Extract the fitted slope coefficient from each fitted model and store them in a list or NumPy array.\r\n",
    "\r\n",
    "Here's the code demonstrating these steps:\r\n",
    "\r\n",
    "```python\r\n",
    "n_simulated_samples = 1000  # Adjust as needed\r\n",
    "simulated_slope_coefficients = []\r\n",
    "\r\n",
    "for _ in range(n_simulated_samples):\r\n",
    "    simulated_data = long_wait_data.copy()\r\n",
    "    simulated_data['duration'] = 1.65 + 0 * simulated_data.waiting + stats.norm(loc=0, scale=0.37).rvs(size=long_wait.sum())\r\n",
    "    fitted_model = smf.ols('duration ~ waiting', data=simulated_data).fit()\r\n",
    "    simulated_slope_coefficients.append(fitted_model.params)\r\n",
    "```\r\n",
    "\r\n",
    "#### **Step 4: Visualize the Bootstrapped and Simulated Sampling Distributions**\r\n",
    "\r\n",
    "Visualize the two sampling distributions of fitted slope coefficients using histograms or density plots. This visualization will allow you to compare the distributions of slope coefficients obtained through bootstrapping (representing the variability in the sample) and simulation under the null hypothesis (representing the expected distribution if there were no linear association).\r\n",
    "\r\n",
    "```python\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "plt.hist(bootstrapped_slope_coefficients, label='Bootstrapped', alpha=0.5)\r\n",
    "plt.hist(simulated_slope_coefficients, label='Simulated (Null)', alpha=0.5)\r\n",
    "plt.xlabel('Fitted Slope Coefficient')\r\n",
    "plt.ylabel('Frequency')\r\n",
    "plt.legend()\r\n",
    "plt.title('Bootstrapped vs. Simulated Sampling Distributions of Slope Coefficients')\r\n",
    "plt.show()\r\n",
    "```\r\n",
    "\r\n",
    "#### **Step 5: Calculate the 95% Bootstrapped Confidence Interval and Simulated p-value**\r\n",
    "\r\n",
    "*   **95% Bootstrapped Confidence Interval:**  To determine if 0 is contained within a 95% bootstrapped confidence interval, use the `np.quantile()` function with the appropriate percentiles:\r\n",
    "\r\n",
    "    ```python\r\n",
    "    confidence_interval = np.quantile(bootstrapped_slope_coefficients, [0.025, 0.975])\r\n",
    "    print(\"95% Bootstrapped Confidence Interval:\", confidence_interval)\r\n",
    "    ```\r\n",
    "\r\n",
    "*   **Simulated p-value:**  Calculate the simulated p-value by determining the proportion of simulated slope coefficients that are as or more extreme than the slope coefficient obtained from fitting a Simple Linear Regression model to the original long wait times data.\r\n",
    "\r\n",
    "    ```python\r\n",
    "    observed_slope = smf.ols('duration ~ waiting', data=long_wait_data).fit().params\r\n",
    "    simulated_p_value = (np.abs(simulated_slope_coefficients) >= np.abs(observed_slope)).mean()\r\n",
    "    print(\"Simulated p-value:\", simulated_p_value)\r\n",
    "    ```\r\n",
    "\r\n",
    "#### **Step 6: Compare the Simulated p-value to the p-value from `smf.ols`**\r\n",
    "\r\n",
    "Finally, compare the simulated p-value you calculated to the p-value reported in `smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().summary().tables`. The two p-values might not match exactly due to the inherent randomness in simulation and the potential differences in the methods used by `smf.ols` to calculate the p-value. However, they should be reasonably close if the simulation accurately reflects the assumptions of the Simple Linear Regression model.\r\n",
    "\r\n",
    "#### **Interpretation and Conclusion**\r\n",
    "\r\n",
    "By following these steps and analyzing the output, you can determine if:\r\n",
    "\r\n",
    "*   The 95% bootstrapped confidence interval contains 0. If it does not, this would provide evidence against the null hypothesis of no linear association.\r\n",
    "*   The simulated p-value matches the p-value reported by `smf.ols`. A close match would suggest that the simulation accurately reflects the model assuothesis tests and confidence intervals might not be reliable.\r\n",
    "\r\n",
    "Please let me know if you have any further questions.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa1148-a1cf-4842-9a69-feb9bdf12127",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 11."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff5a22-ecf1-4c48-8fcc-b512d33250f0",
   "metadata": {},
   "source": [
    "Indicator Variables in Simple Linear Regression for Comparing Eruption Durations\r\n",
    "\r\n",
    "Let's examine the provided Simple Linear Regression model specification using an indicator variable and compare it to previous models from our conversation. This model aims to assess the differences in average eruption durations between \"short\" and \"long\" wait times at Old Faithful.\r\n",
    "\r\n",
    "#### **Understanding the Indicator Variable Model**\r\n",
    "\r\n",
    "The model specification you've given is:\r\n",
    "\r\n",
    "```\r\n",
    "Y_i = β_intercept + 1_{[\"long\"]}(k_i) β_contrast + ε_i where ε_i ~ N(0, σ)\r\n",
    "```\r\n",
    "\r\n",
    "*   **`Y_i`**: This represents the eruption duration for the *i*-th observation.\r\n",
    "*   **`β_intercept`**: This is the intercept coefficient, representing the average eruption duration when the wait time is \"short\" (because the indicator variable will be 0).\r\n",
    "*   **`1_{[\"long\"]}(k_i)`**: This is an indicator variable (a binary variable). It takes the value 1 if the *i*-th observation's `kind` (`k_i`) is \"long\" and 0 otherwise.\r\n",
    "*   **`β_contrast`**: This is the contrast coefficient, representing the average difference in eruption duration between \"long\" and \"short\" wait times.\r\n",
    "*   **`ε_i`**: This is the error term, assumed to be normally distributed with mean 0 and standard deviation `σ`.\r\n",
    "\r\n",
    "#### **Comparing Model Specifications**\r\n",
    "\r\n",
    "Here's a breakdown of the differences between this indicator variable model and the previously considered models:\r\n",
    "\r\n",
    "1.  **`smf.ols('duration ~ waiting', data=old_faithful)`:** This model uses `waiting` as a continuous predictor to model eruption duration across all data points. It assumes a linear relationship between waiting time and eruption duration across the entire range of waiting times.\r\n",
    "2.  **`smf.ols('duration ~ waiting', data=old_faithful[short_wait])` and `smf.ols('duration ~ waiting', data=old_faithful[long_wait])`**: These models fit separate Simple Linear Regression models for \"short\" and \"long\" wait times, respectively. They allow for different linear relationships between waiting time and eruption duration within each group. However, they do not directly estimate the difference between the groups' average eruption durations.\r\n",
    "3.  **Indicator Variable Model:** This model uses a categorical predictor (`kind`) to directly estimate the average difference in eruption durations between \"short\" and \"long\" wait times. It assumes that the relationship between waiting time and eruption duration can be captured by a single intercept for \"short\" wait times and a contrast representing the difference between \"long\" and \"short\" wait times.\r\n",
    "\r\n",
    "#### **Analyzing the Output**\r\n",
    "\r\n",
    "You've provided the output of the indicator variable model:\r\n",
    "\r\n",
    "```python\r\n",
    "from IPython.display import display\r\n",
    "\r\n",
    "display(smf.ols('duration ~ C(kind, Treatment(reference=\"short\"))', data=old_faithful).fit().summary().tables)\r\n",
    "```\r\n",
    "\r\n",
    "The key values to focus on are:\r\n",
    "\r\n",
    "*   **`Intercept`**: The estimated average eruption duration for \"short\" wait times is approximately 3.8783 minutes.\r\n",
    "*   **`C(kind, Treatment(reference=\"short\"))[T.long]`**: The estimated contrast is approximately 1.2357 minutes. This suggests that, on average, eruptions following \"long\" wait times are 1.2357 minutes longer than those following \"short\" wait times.\r\n",
    "*   **`P>|t|`**: The p-value associated with the contrast is very small (approximately 0.000). This indicates **very strong evidence** against the null hypothesis of no difference in average eruption duration between \"short\" and \"long\" wait times.\r\n",
    "\r\n",
    "#### **Box Plot Visualization**\r\n",
    "\r\n",
    "The box plot you've provided:\r\n",
    "\r\n",
    "```python\r\n",
    "fig = px.box(old_faithful, x='kind', y='duration', \r\n",
    "             title='duration ~ kind',\r\n",
    "             category_orders={'kind': ['short', 'long']})\r\n",
    "fig.show()\r\n",
    "```\r\n",
    "\r\n",
    "visually confirms the difference in average eruption durations between the two groups. The box plot for \"long\" wait times is clearly shifted upwards compared to the box plot for \"short\" wait times, supporting the conclusion of a significant difference in average eruption durations.\r\n",
    "\r\n",
    "#### **Conclusion**\r\n",
    "\r\n",
    "By using an indicator variable in the Simple Linear Regression model, we were able to directly estimate and test the difference in average eruption durations between \"short\" and \"long\" wait times. The very small p-value provides strong evidence against the null hypothesis of no difference. This analysis, combined with the box plot visualization, supports the conclusion that eruptions following \"long\" wait times at Old Faithful are, on average, significantly longer than those following \"short\" wait times.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d7ac5-3532-4fca-9550-abb579aaa820",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b159fd3-78a7-4a9b-9e30-4d7a5df75816",
   "metadata": {},
   "source": [
    "Assessing Normality of Residuals from Histograms\r\n",
    "\r\n",
    "The provided code generates histograms of residuals from four different Simple Linear Regression models fitted to the Old Faithful Geyser dataset.   These histograms can be used to assess the plausibility of the assumption that the error terms in each model are normally distributed.\r\n",
    "\r\n",
    "Let's examine each histogram individually:\r\n",
    "\r\n",
    "1.    **Model 1: All Data using slope:** This model uses waiting time as a continuous predictor for eruption duration across the entire dataset.   Examining the histogram, the distribution of residuals appears to be **bimodal (having two peaks)**, which is a clear departure from a normal distribution.   The presence of bimodality suggests that there might be two distinct subgroups within the data that exhibit different relationships between waiting time and eruption duration.   This violation of the normality assumption raises concerns about the reliability of p-values and confidence intervals obtained from this model.\r\n",
    "\r\n",
    "2.    **Model 2: Short Wait Data:** This model focuses on data points where the waiting time is relatively short.   The histogram of residuals for this model still shows some degree of **bimodality, although less pronounced** than in Model 1.   The distribution is slightly **skewed to the right**.   These deviations from normality, though less severe, still cast some doubt on the assumption of normally distributed error terms.\r\n",
    "\r\n",
    "3.    **Model 3: Long Wait Data:** This model examines data points with longer waiting times.   The histogram of residuals for this model exhibits a more **unimodal shape** compared to Models 1 and 2.   However, there is a noticeable **skew to the left**.   This skewness suggests that the distribution of residuals is not perfectly normal, which could impact the accuracy of inferences drawn from this model.\r\n",
    "\r\n",
    "4.    **Model 4: All Data using indicator:** This model uses a categorical predictor (kind) to distinguish between \"short\" and \"long\" wait times.   The histogram of residuals for this model displays the **closest resemblance to a normal distribution** among the four models.   The distribution is relatively symmetrical and unimodal, with no strong skewness or multiple peaks.   Based on this histogram, the assumption of normally distributed error terms seems more plausible for this model compared to the others.\r\n",
    "\r\n",
    "#### **Conclusions and Implications**\r\n",
    "\r\n",
    "The histograms reveal that the assumption of normally distributed error terms is not fully supported for all four models.   Models 1, 2, and 3 show clear departures from normality, while Model 4 exhibits the best approximation of a normal distribution.\r\n",
    "\r\n",
    "*   These findings highlight the importance of **diagnosing model assumptions** using residuals.   Relying on models that violate key assumptions can lead to inaccurate conclusions and misleading interpretations.\r\n",
    "*   The fact that Model 4, which uses a categorical predictor, shows a more normal distribution of residuals suggests that **considering the categorical nature of waiting time** (short vs. long) might be a more appropriate way to model the relationship with eruption duration in the Old Faithful dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f0bf46-bfeb-4240-a8ae-42ca98575703",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 13."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839caab-7a96-4ea2-9ea9-87b802765a10",
   "metadata": {},
   "source": [
    "Comparing Permutation Testing, Bootstrapping, and Indicator Variable Models for Two-Sample Comparisons\r\n",
    "\r\n",
    "The query requests an explanation and comparison of three approaches for comparing two groups when the data does not involve paired measurements: permutation testing, bootstrapping, and the indicator variable model.\r\n",
    "\r\n",
    "#### (A) Permutation Test by Shuffling Labels: Hypothesis Testing for Group Differences\r\n",
    "\r\n",
    "A permutation test, also known as a randomization test, is a non-parametric method to test the null hypothesis of no difference between two groups.  Here's how it works for comparing the means of two groups:\r\n",
    "\r\n",
    "1.  **State the null hypothesis:** The null hypothesis is that there is no difference in the means of the two populations the samples were drawn from.\r\n",
    "2.  **Calculate the observed test statistic:**  This is usually the difference in the sample means of the two groups.\r\n",
    "3.  **Shuffle the group labels:** Repeatedly shuffle the group labels of the data points while keeping the values themselves fixed. This simulates the data we would expect to see if the null hypothesis were true - that is, if group membership had no effect on the outcome variable.\r\n",
    "4.  **Calculate the test statistic for each shuffled sample:** For each shuffled dataset, calculate the difference in means between the two \"groups\" defined by the shuffled labels.\r\n",
    "5.  **Generate the sampling distribution under the null:** The distribution of the test statistics from the shuffled datasets represents the sampling distribution of the test statistic under the null hypothesis of no group difference.\r\n",
    "6.  **Calculate the p-value:** The p-value is the proportion of test statistics from the shuffled datasets that are as or more extreme than the observed test statistic. A small p-value provides evidence against the null hypothesis, suggesting a difference between the groups.\r\n",
    "\r\n",
    "#### (B) 95% Bootstrap Confidence Interval for the Difference in Means: Inference for Group Differences\r\n",
    "\r\n",
    "Bootstrapping is a resampling method to estimate the uncertainty of a sample statistic. In the two-sample context, this is called \"double bootstrapping\" because each sample is bootstrapped independently. Here's how to create a bootstrap confidence interval for the difference in means:\r\n",
    "\r\n",
    "1.  **Resample with replacement from each group:** For each group, repeatedly draw bootstrap samples of the same size as the original group, with replacement. This simulates multiple datasets from each group, reflecting the variability within each group.\r\n",
    "2.  **Calculate the difference in means for each pair of bootstrap samples:** For each pair of bootstrap samples, calculate the difference in means.\r\n",
    "3.  **Generate the bootstrapped sampling distribution:** The distribution of the differences in means represents the bootstrapped sampling distribution of the difference in means, reflecting the uncertainty in this estimate.\r\n",
    "4.  **Calculate the confidence interval:** The 95% confidence interval is defined by the 2.5th and 97.5th percentiles of the bootstrapped sampling distribution of the difference in means.  This interval provides a range of plausible values for the true difference in population means.\r\n",
    "\r\n",
    "#### (a) Explanation of Sampling Approaches in the Simulations:\r\n",
    "\r\n",
    "*   **Permutation Test:**  The sampling approach in permutation testing involves randomly shuffling the group labels to create simulated datasets under the null hypothesis of no group difference. This simulates what would happen if group membership was arbitrary and had no effect on the outcome variable. By comparing the observed test statistic to the distribution of test statistics from the shuffled datasets, we can assess the evidence against the null hypothesis.\r\n",
    "*   **Bootstrap Confidence Interval:** The sampling approach in \"double bootstrapping\" involves resampling with replacement within each group to create multiple bootstrap samples. These bootstrap samples are then used to calculate the difference in means, allowing us to estimate the variability of this difference and construct a confidence interval for the true difference in population means.\r\n",
    "\r\n",
    "#### (b) Comparison with Indicator Variable Based Model Approach:\r\n",
    "\r\n",
    "The indicator variable based model approach, as used in simple linear regression, is a parametric method that uses an indicator variable to represent group membership. This model estimates the difference in means between the groups through the coefficient of the indicator variable.\r\n",
    "\r\n",
    "##### Similarities:\r\n",
    "\r\n",
    "*   **All three methods aim to compare two groups.** Whether through hypothesis testing (permutation test) or inference (bootstrap confidence interval and indicator variable model), the goal is to assess if there's a difference between the two groups.\r\n",
    "*   **They rely on the concept of sampling distributions.** Both permutation testing and bootstrapping involve creating sampling distributions to understand the variability of a statistic under certain conditions, which is also the basis for hypothesis testing and confidence intervals in the indicator variable model.\r\n",
    "\r\n",
    "##### Differences:\r\n",
    "\r\n",
    "*   **Parametric vs. Non-parametric:** Permutation testing and bootstrapping are non-parametric methods, meaning they don't rely on distributional assumptions about the data. The indicator variable model, in contrast, is a parametric method, assuming the error terms in the model are normally distributed. \r\n",
    "*   **Focus:**  \r\n",
    "    *   Permutation testing focuses on **hypothesis testing**, providing a p-value to evaluate the evidence against the null hypothesis of no difference.\r\n",
    "    *   Bootstrapping focuses on **inference**, generating a confidence interval to estimate the range of plausible values for the true difference in means.\r\n",
    "    *   The indicator variable model can be used for **both hypothesis testing and inference**, providing a p-value for the indicator variable coefficient and a confidence interval for the estimated difference in means.\r\n",
    "*   **Assumptions:** Bootstrapping generally requires fewer assumptions than the indicator variable model, which relies on assumptions like linearity, independence of errors, and constant variance.\r\n",
    "\r\n",
    "#### Which Method to Use?\r\n",
    "\r\n",
    "The choice of method depends on the research question, the nature of the data, and the desired type of analysis.\r\n",
    "\r\n",
    "*   **Permutation tests are powerful and robust when distributional assumptions are not met.** However, they are computationally intensive, especially for large datasets.\r\n",
    "*   **Bootstrapping is flexible and can be applied to a wider range of statistics**, not just the mean. However, it can also be computationally intensive, and the results can be sensitive to the number of bootstrap samples.\r\n",
    "*   **The indicator variable model is computationally efficient and provides both hypothesis testing and inference.** However, it relies on assumptions that need to be carefully assessed.\r\n",
    "\r\n",
    "**It is important to understand the strengths and limitations of each method to choose the most appropriate one for your analysis**.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecac512-dfb1-44f8-a570-43c7f079fb74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 14."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784ad1c-f0d7-468d-94f0-7195f29a85ec",
   "metadata": {},
   "source": [
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe296d65-49e1-43b7-a250-a86a1e5e923e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# STA130 Custom NBLM Chatbot conversation summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7297f-859b-42ea-a60b-86d1a98cd48a",
   "metadata": {},
   "source": [
    "### Summary of Interactions Regarding Two-Sample Comparisons\r\n",
    "\r\n",
    "The conversation focused on understanding and comparing different methods for comparing two groups when \"before and after\" data is not available, meaning there are no natural pairs for calculating differences for a \"one sample\" (paired differences) hypothesis test. \r\n",
    "\r\n",
    "The query specifically requested a comparison between:\r\n",
    "\r\n",
    "* **(A) Permutation Testing:** This approach involves shuffling group labels to simulate datasets under the null hypothesis of no difference between the groups. \r\n",
    "* **(B) 95% Bootstrap Confidence Interval:**  This method involves resampling within each group and calculating the difference in means between the bootstrap samples to create a confidence interval for the true difference in population means.\r\n",
    "* **Indicator Variable Model:**  This method, used in simple linear regression, uses an indicator variable to represent group membership, and the coefficient of this variable estimates the difference in means between the groups.\r\n",
    "\r\n",
    "The response provided detailed explanations of each method and compared their sampling approaches, focusing on how they address the question of group differences. \r\n",
    "\r\n",
    "#### Similarities:\r\n",
    "\r\n",
    "* All three methods aim to compare two groups.\r\n",
    "* All three methods rely on the concept of sampling distributions.\r\n",
    "\r\n",
    "#### Differences:\r\n",
    "\r\n",
    "* **Parametric vs. Non-parametric:**\r\n",
    "    * Permutation tests and bootstrapping are **non-parametric**, making no distributional assumptions about the data.\r\n",
    "    * The indicator variable model is **parametric**, assuming normally distributed errors in the model.\r\n",
    "* **Focus:**\r\n",
    "    * Permutation tests focus on **hypothesis testing**, yielding a p-value to evaluate the null hypothesis of no difference.\r\n",
    "    * Bootstrapping focuses on **inference**, generating a confidence interval for the difference in means.\r\n",
    "    * The indicator variable model can be used for **both hypothesis testing and inference**.\r\n",
    "* **Assumptions:**\r\n",
    "    * Bootstrapping requires fewer assumptions than the indicator variable model, which relies on assumptions like linearity, independence of errors, and constant variance.\r\n",
    "\r\n",
    "#### Which Method to Use?\r\n",
    "\r\n",
    "The response emphasized that the choice of method depends on several factors, including:\r\n",
    "\r\n",
    "* The research question.\r\n",
    "* The nature of the data.\r\n",
    "* The type of analysis desired.\r\n",
    "\r\n",
    "It highlighted the strengths and limitations of each approach:\r\n",
    "\r\n",
    "* **Permutation tests** are powerful and robust when distributional assumptions aren't met, but computationally intensive for large datasets.\r\n",
    "* **Bootstrapping** is flexible and applicable to various statistics but computationally intensive, and results can be sensitive to the number of bootstrap samples.\r\n",
    "* **The indicator variable model** is computationally efficient and provides both hypothesis testing and inference, but relies on assumptions that need careful assessment.\r\n",
    "\r\n",
    "The response concluded by stressing the importance of understanding each method's strengths and limitations to select the most appropriate one for a given analysis.\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
